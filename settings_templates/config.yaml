# Main settings for Discord, Textgen, Imggen, and TTSgen

# Discord settings. Be sure to add your bot token to 'bot_token.yaml'
discord:
  # This setting is recommended if you configure the bot to generate large files via APIs. Needs additional config in 'dict_api_settings.yaml' (see 'misc_api_functions').
  upload_large_files: false
  # Feature for the bot to automatically react to messages to indicate special attributes in chat history (hidden, regenerated, continued, etc)
  history_reactions:
    enabled: true
    hidden_emoji: 'üôà'
    regen_emoji: 'üîÉ'
    continue_emoji: '‚è©'
  direct_messages:
    allow_chatting: true # Allows the bot to interact in direct messages (DMs). Note: Most commands are disabled by default.
    allowed_commands: ['image', 'speak', 'prompt']  # Exclude commands by removing them from list. [] = all disabled
  embed_settings:
    color: 0x1e1f22 # Customize your embeds (0x_______) https://imagecolorpicker.com/
    show_embeds:    # Set false for any embeds you wish disabled
      system: true  # Information / System messages
      images: true  # Embeds related to image generation
      changes: true # Embeds related to character / model changes
      flows: true   # Embeds for the Flows feature
  # Feature for bot to copy current settings in a dedicated channel when changing settings via commands (ei: /imgmodel).
  post_active_settings:
    enabled: true # When enabled, you can set a "Settings Channel" for each server the bot is in via command '/set_server_settings_channel'
    post_settings_for: ['behavior', 'character', 'tags', 'imgmodel', 'llmstate'] # Limit the settings to be posted by removing them from list.
  # Feature for bot to automatically send a copy of image to starboard channel.
  starboard:
    enabled: true
    min_reactions: 2                        # number of reactions
    emoji_specific: false
    react_emojis: ['‚úÖ', 'üëè']             # for if 'emoji_specific: true'
    target_channel_id: 11111111111111111111 # bot requires message / msg management permissions

# Whitelist for locations the bot may read/write files (in addition to local dir which is allowed by default)
allowed_paths: []
#  - 'C:\ComfyUI_windows_portable\ComfyUI\input'

# Your setup may allow more/less requests to be processed than default. Food for thought: using light/medium weight AI models can allow you to significantly increase these numbers.
task_queues:
  maximum_concurrency: 4 # maximum number of tasks that can run simultaneously at any given time
  # NOTE: The bot will intelligently not process message/history tasks concurrently, if the requests are from the same channel.
  message_queue_concurrency: 1 # Chat message requests (LLM Gen)
  history_queue_concurrency: 1 # History management tasks (some lighter than others, including: regenerate / continue / reset convo / change char / edit history / etc)
  gen_queue_concurrency: 1     # GPU/CPU intensive tasks (IMG Gen / model changes / etc)
  normal_queue_concurrency: 3  # lightweight tasks

# If enabled, user settings will be managed seperately for each server (excluding the settings here in config.yaml)
per_server_settings:
  enabled: false
  # The following settings only apply if 'enabled = true'
  per_server_characters: false # **If enabled, all characters must share the same avatar.**
  character_avatar: '' # The name of an image file in your '/user/images' directory. Do not include the extension (.png/.jpg/.gif)
  # Only enable the following if: (1) You have lots of free VRAM (2) Your client settings allow multiple models to be loaded in VRAM.
  per_server_imgmodel_settings: false # In addition to separate internal settings, this uses the payload to drive model handling (instead of /models API).

# Dynamic Prompting feature. Uses similar syntax and usage as the SD WebUI extension 'sd-dynamic-prompts'.
# More details here: https://github.com/altoiddealer/ad_discordbot/wiki/dynamic-prompting
dynamic_prompting_enabled: true


# Textgen settings
# Note: Many native textgen-webui settings are honored: 'CMD_FLAGS.txt' (extensions) / 'user_data/settings.yaml' / 'user_data/models/config-user.yaml' (LLM model settings)
textgen:
  enabled: true                     # Controls whether the script initializes with text generation features
  # History handling settings.
  chat_history:
    limit_history: true             # Limits the stored history to roughly the current 'truncation_length' (more than enough retained). You may have performance issues if set to false.
    export_for_tgwui: true          # Defines if your history save can be later imported into standalone text-generation-webui.
    autoload_history: false         # Set to true if you want the character to load with the most recently saved chat history.
    change_char_history_method: new # 'new' - start new history; 'keep' - retain history for next character (only applicable if 'autoload_history: true')
    per_channel_history: true       # If true, each channel will have its own chat history. Log files will not be compatible with text-generation-webui unless processed by .bat in '/utils/'


# TTS settings. Use command '/set_server_voice_channel' in each server that you want to connect to voice channel for playing TTS
# If enabled, either: check API configuration in 'dict_api_settings.yaml' OR use 'tgwui_extension' (below)
ttsgen:
  enabled: false
  play_mode: 2                  # 0 = use voice channel / 1 = upload file to chat channel / 2 = both (use voice & upload file)
  mp3_bit_rate: 128             # If play_mode = 1 or 2, and the output (.wav) exceeds 8MB (discord limit), it will convert to .mp3 before uploading.
  save_mode: 1                  # 0 = save outputs / 1 = try deleting outputs. Note: Can't delete outputs uploaded to channel. (../extensions/coqui_tts/outputs)
  tts_greeting: true            # Whether to generate TTS for greeting when using '/character' or '/reset_conversation'
  tts_streaming: true           # Only valid if character behavior has `chance_to_stream_reply`. Set to "false" if you want text streaming and TTS, but not TTS streaming.
  # Extension method (non-API) only works with TGWUI integrated install.
  # Supported TTS extensions: 'alltalk_tts', 'coqui_tts', 'silero_tts', 'edge_tts' and 'elevenlabs_tts' have been tested. Additional tts extensions may work.
  tgwui_extension: ''           # '' = Disabled.   Example: 'alltalk_tts' (Loads automatically! Don't include in '--extensions' launch flag!)


# Imggen settings. If enabled, check API configuration in 'dict_api_settings.yaml'
imggen:
  enabled: true                 # Controls whether SD WebUI is part of the bot (does not register relavent commands for discord, etc)
  # The following are only applicable for A1111 / Forge / ReForge (the bot will detect this via API)
  extensions:                   # Only set extensions as True if they are installed AND active in your A1111.
    controlnet_enabled: false   # Requires: sd-webui-controlnet (https://github.com/Mikubill/sd-webui-controlnet) AND configuring 'dict_cmdoptions.yaml'
    forgecouple_enabled: false  # Requires: sd-forge-couple (https://github.com/Haoming02/sd-forge-couple) **Only works for Forge**
    layerdiffuse_enabled: false # Requires: sd-forge-layerdiffuse (https://github.com/layerdiffusion/sd-forge-layerdiffuse) **Only works for Forge**
    reactor_enabled: false      # Requires: sd-webui-reactor (https://github.com/Gourieff/sd-webui-reactor)
    # 'sd-loractl' extension enhances LORA processing by allowing adjustable weights during image generation.
    # This bot can automatically calculate and apply weight scaling as defined below.
    loractl:                    # Requires: sd-webui-loractl (https://github.com/cheald/sd-webui-loractl) OR ReForge (it's built in!)
      enabled: false
      min_loras: 2              # Minimum number of loras in the prompt to trigger the following weight scaling definitions.
      # format is (% of existing lora weight)@(step percent),(more step definitions). These are not static weights- these are multiplied by the existing LORA weight. '1.0@0' = begin generation with existing LORA weight.
      # You can define as many steps as you want. ex1: '0.5@0' would just cut the LORA weight in half. ex2: '0.0@0,1.0@0.5,0.0@1.0' would look like a pyramid on the graph.
      lora_1_scaling: '1.0@0,0.5@0.5'
      lora_2_scaling: '0.5@0,1.0@0.5'
      # More scaling definitions can be added ex: 'lora_3_scaling' etc
      # Applies to LORAs when there are more in the prompt than defined above. ei: If 4 loras are found in prompt, but only defined up to lora_2_scaling, then the last 2 LORAs would be scaled by this definition.
      additional_loras_scaling: '0.4@0.0,0.8@0.5'
