# These are the baseline settings you may adjust to your liking.
# When you use bot commands like /character, /imgmodel, etc - those settings will have higher priority.
# Note that Img model settings defined here DO NOT get merged until the bot changes Img models (via '/imgmodel' cmd, or the 'auto change Img models' feature).

# To see the currently active settings, look in internal/activesettings.yaml (which is not intended to be edited).

# There are many settings here you probably don't need to tinker with.

behavior:
  reply_to_itself: 0.0                # 0.0 = never happens / 1.0 = always happens
  chance_to_reply_to_other_bots: 0.0  # Chance for bot to reply when other bots speak in main channel
  reply_to_bots_when_addressed: 0.0   # Chance for bot to reply when other bots mention it by name
  only_speak_when_spoken_to: true     # This value gets ignored if you're talking in the bot's main channel
  ignore_parentheses: true            # (Bot ignores you if you write like this)
  go_wild_in_channel: true            # Whether or not the bot will always reply in the main channel
  conversation_recency: 600           # How long (in seconds) a user is determined to be "in active conversation". Only applicable if 'go_wild_in_channel' is false

imgmodel:
  imgmodel_url: ''
  override_settings:
    CLIP_stop_at_last_layers: 1
    sd_model_checkpoint: ''
    sd_vae: Automatic
  payload:
    restore_faces: False
    sampler_name: "DPM++ 2M"
    scheduler: karras
    steps: 30
    cfg_scale: 7
    height: 896
    width: 1152
    enable_hr: False
    hr_upscaler: "Latent"
    denoising_strength: 0.5
    hr_scale: 2
    hr_second_pass_steps: 0
    # Note: Refiner is disabled if 'refiner_switch_at: 0.0' *OR* refiner_checkpoint: ''
    refiner_checkpoint: '' # 'sd_xl_refiner_1.0_0.9vae.safetensors [8d0ce6c016]'
    refiner_switch_at: 0.8
    # inpainting params
    mask_blur: 4                  # blur strength
    inpainting_fill: 1            # 0 - 'fill' / 1 - 'original' / 2 - 'latent noise' / 3 - 'latent nothing'
    inpaint_full_res: true        # true - 'Whole picture' / false - 'Only masked'
    inpaint_full_res_padding: 32  # 'Only masked padding, pixels' (default: 32)
    inpainting_mask_invert: 0     # 0 - 'Inpaint masked', 1 - 'Inpaint not masked'
    # Stable Diffusion (A1111 / Forge) extension settings. Modifying these may have unintended results...
    alwayson_scripts:
      controlnet:           # ControlNet extension arguments. The 'tags' feature supports multi-controlnet. To enable multi-controlnet, first increase # of CNets in A1111/Forge CNet settings.
        args:               # Then, use 'cnet0_{key}: value' tags for first unit, and 'cnet1_{key}' etc, for additional ControlNets.
          - enabled: false        # Enable ControlNet
            image: null           # base64 string for an input image
            mask_image: null      # base64 string for a greyscale mask image
            model: "None"         # Exact name of the model including hash (ex: "diffusers_xl_canny_full [2b69fca4]")
            module: "None"        # The preprocessor, such as "canny". "None" = No preprocessor (treat input image as a ControlNet mask)
            weight: 1.0           # strength of the ControlNet
            processor_res: 64     # resolution of the ControlNet guidance
            pixel_perfect: true   # ** overrides 'preprocessor_res' by dynamically using the resolution of the input image **
            guidance_start: 0.0   # 0.0 = begin guidance on step 1, 1.0 = never start guidance
            guidance_end: 1.0     # 0.0 = end on step 1, 1.0 = does not end guidance
            threshold_a: 64       # Only relavent for certain model types. Refer to ControlNet in your SD WebUI.
            threshold_b: 64       # Only relavent for certain model types. Refer to ControlNet in your SD WebUI.
            control_mode: 0       # 0 - Balanced, 1 - Prompt is More Important, 2 - ControlNet is More Important
            resize_mode: 1        # 0 - Just Resize, 1 - Crop and Resize, 2 - Resize and Fill
            lowvram: false        # Reduces vram usage by increasing generation time
            save_detected_map: false  # Whether control maps should be returned
      forge_couple:          # Forge Couple extension arguments. More info here: (https://github.com/Haoming02/sd-forge-couple/wiki/API)
        args:
          enable: false                 # Enable Forge Couple
          mode: 'Basic'                 # 'Basic' (uses 'direction') / 'Advanced' (uses 'maps') / 'Mask' (uses 'maps')
          sep: 'SEP'                    # Separator such as 'SEP'. If empty, '\n' (line breaks) will separate regions.
          direction: 'Horizontal'       # 'Horizontal' / 'Vertical'
          global_effect: 'First Line'   # 'None' / 'First Line' / 'Last Line' (defines if and where a global prompt will be in your prompt structure (affecting all regions))
          global_weight: 0.5            # The Weight of the Global Effect.
          maps: [                         # for advanced regional mapping. Format for each region map: [ x / y / weight ]. Valid range for each value is 0.0 - 1.0
            ["0:0.5", "0.0:1.0", "1.0"],  # if 'mode: Advanced', then 'maps' should be a list of lists as shown in default value [[ x, y, weight ], [x,... ]]
            ["0.5:1.0","0.0:1.0","1.0"]   # if 'mode: Mask', then 'maps' should be a list of dictionaries [{'mask': <base64>, 'weight:' 1.0}, {'mask'...}] )
            ]
      layerdiffuse:         # layerdiffuse extension arguments
        args:               
          enabled: false                  # Enable layerdiffuse
          method: '(SDXL) Only Generate Transparent Image (Attention Injection)' # Method
          weight: 1.0                     # Weight of alpha channel (0.0 - 1.0)
          stop_at: 1.0                    # Stop at (0.0 - 1.0)
          foreground: null                # Foreground setting (if foreground method)
          background: null                # Background setting (if background method)
          blending: null                  # Blending (for foreground/background methods)
          resize_mode: 'Crop and Resize'  # Resize mode
          output_mat_for_i2i: false       # Output original mat for img2img
          fg_prompt: ''                   # Foreground Additional Prompt
          bg_prompt: ''                   # Background Additional Prompt
          blended_prompt: ''              # Blended Additional Prompt
      reactor:              # Reactor extension arguments
        args:                   # ** These defaults can be customized. It's OK if missing from here - the bot will fall back to default values in bot.py **
          image: ''                     #0 source face image in base64
          enabled: false                #1 Enable ReActor
          source_faces: '0'             #2 Comma separated face number(s) from swap-source image
          target_faces: '0'             #3 Comma separated face number(s) for target image (result)
          model: inswapper_128.onnx     #4 model path
          restore_face: CodeFormer      #5 Restore Face: None; CodeFormer; GFPGAN
          restore_visibility: 1         #6 Restore visibility value
          restore_upscale: true         #7 Restore face -> Upscale
          upscaler: 4x_NMKD-Superscale-SP_178000_G  #8 Upscaler (type 'None' if doesn't need), see full list here: http://127.0.0.1:7860/sdapi/v1/script-info -> reactor -> sec.8
          scale: 1.5                    #9 Upscaler scale value
          upscaler_visibility: 1        #10 Upscaler visibility (if scale = 1)
          swap_in_source_img: false     #11 Swap in source image
          swap_in_gen_img: true         #12 Swap in generated image
          log_level: 1                  #13 Console Log Level (0 - min, 1 - med or 2 - max)
          gender_detect_source: 0       #14 Gender Detection (Source) (0 - No, 1 - Female Only, 2 - Male Only)
          gender_detect_target: 0       #15 Gender Detection (Target) (0 - No, 1 - Female Only, 2 - Male Only)
          save_original: false          #16 Save the original image(s) made before swapping
          codeformer_weight: 0.8        #17 CodeFormer Weight (0 = maximum effect, 1 = minimum effect), 0.5 - by default
          source_img_hash_check: false  #18 Source Image Hash Check, False - by default
          target_img_hash_check: false  #19 Target Image Hash Check, False - by default
          system: CUDA                  #20 CPU or CUDA (if you have it), CPU - by default
          face_mask_correction: true    #21 Face Mask Correction
          source_type: 0                #22 Select Source, 0 - Image, 1 - Face Model, 2 - Source Folder
          face_model: ''                #23 Filename of the face model (from "models/reactor/faces"), e.g. elena.safetensors, don't forger to set #22 to 1
          source_folder: ''             #24 The path to the folder containing source faces images, don't forger to set #22 to 2
          multiple_source_images: null  #25 **irrelevant for API**
          random_img: true              #26 Randomly select an image from the path
          force_upscale: true           #27 Force Upscale even if no face found
          threshold: 0.6                #28 Face Detection Threshold
          max_faces: 2                  #29 Maximum number of faces to detect (0 is unlimited)

llmcontext:
  bot_description: ''
  bot_emoji: ''
  context: 'The following is a conversation with an AI Large Language Model. The AI has been trained to answer questions, provide recommendations, and help with decision making. The AI follows user requests. The AI thinks outside the box.'
  extensions: {}
  greeting: 'How can I help you today?'
  name: 'AI'
  use_voice_channel: false

llmstate:
  state:
    preset: ''  # Name of a file in '/presets' (ex. 'Midnight Enigma'). Preset settings will override values defined here.
    grammar_string: ''
    add_bos_token: true
    auto_max_new_tokens: false
    ban_eos_token: false
    character_menu: ''
    chat_generation_attempts: 1
    chat_prompt_size: 2048
    custom_stopping_strings: ''
    custom_system_message: ''
    custom_token_bans: ''
    do_sample: true
    dynamic_temperature: False
    dynatemp_low: 1
    dynatemp_high: 1
    dynatemp_exponent: 1
    encoder_repetition_penalty: 1
    epsilon_cutoff: 0
    eta_cutoff: 0
    frequency_penalty: 0
    greeting: ''
    guidance_scale: 1
    history:
      internal: []
      visible: []
    max_new_tokens: 512
    max_tokens_second: 0
    max_updates_second: 0
    min_p: 0.00
    mirostat_eta: 0.1
    mirostat_mode: 0
    mirostat_tau: 5
    mode: 'chat'    # chat / chat-instruct / instruct
    name1: ''           # name1 and name2
    name1_instruct: ''  # are automatically
    name2: ''           # populated, so
    name2_instruct: ''  # ignore these.
    negative_prompt: ''
    no_repeat_ngram_size: 0
    penalty_alpha: 0
    presence_penalty: 0
    prompt_lookup_num_tokens: 0
    repetition_penalty: 1.18
    repetition_penalty_range: 1024
    sampler_priority: []
    seed: -1.0
    skip_special_tokens: true
    stop_at_newline: false
    stopping_strings: ''
    stream: true
    temperature: 0.98
    temperature_last: false
    tfs: 1
    top_a: 0
    top_k: 100
    top_p: 0.37
    truncation_length: 2048
    turn_template: ''
    typical_p: 1
    user_bio: ''
    chat_template_str: >-
      {%- for message in messages %}
          {%- if message['role'] == 'system' -%}
              {{- message['content'] + '\n\n' -}}
          {%- else -%}
              {%- if message['role'] == 'user' -%}
                  {{- name1 + ': ' + message['content'] + '\n'-}}
              {%- else -%}
                  {{- name2 + ': ' + message['content'] + '\n' -}}
              {%- endif -%}
          {%- endif -%}
      {%- endfor -%}
    # The script will only initialize with this instruct template if one is not defined in the LLM model's metadata.
    instruction_template_str: >-
      {%- set ns = namespace(found=false) -%}
      {%- for message in messages -%}
          {%- if message['role'] == 'system' -%}
              {%- set ns.found = true -%}
          {%- endif -%}
      {%- endfor -%}
      {%- if not ns.found -%}
          {{- '' + 'Below is an instruction that describes a task. Write a response that appropriately completes the request.' + '\n\n' -}}
      {%- endif %}
      {%- for message in messages %}
          {%- if message['role'] == 'system' -%}
              {{- '' + message['content'] + '\n\n' -}}
          {%- else -%}
              {%- if message['role'] == 'user' -%}
                  {{-'### Instruction:\n' + message['content'] + '\n\n'-}}
              {%- else -%}
                  {{-'### Response:\n' + message['content'] + '\n\n' -}}
              {%- endif -%}
          {%- endif -%}
      {%- endfor -%}
      {%- if add_generation_prompt -%}
          {{-'### Response:\n'-}}
      {%- endif -%}
    # <|character|> gets replaced by the bot name, and <|prompt|> gets replaced by the regular chat prompt.
    chat-instruct_command: >-
      Continue the chat dialogue below. Write a single reply for the character "<|character|>".\n
      \n
      <|prompt|>